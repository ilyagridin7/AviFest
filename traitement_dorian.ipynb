{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "from itertools import tee\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from ipywidgets import widgets\n",
    "import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialisation de MongoDB & Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# client.drop_database('AviFest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la base de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client['AviFest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x2b8d0b4e980>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = db['price']\n",
    "prices.insert_many([\n",
    "    {'type': 'performance', 'price': 10},\n",
    "    {'type': 'indiscipline', 'price': 20},\n",
    "    {'type': 'spectacle', 'price': 30},\n",
    "    {'type': 'théâtre', 'price': 40},\n",
    "    {'type': 'dance', 'price': 50},\n",
    "    {'type': 'installation photographique', 'price': 60},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = db['users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(row):\n",
    "    row['gender'] = row['gender'][0]\n",
    "    firstname, lastname = row['name'].split(' ')\n",
    "    row['firstname'] = firstname\n",
    "    row['lastname'] = lastname\n",
    "    \n",
    "    del row['name']\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = spark.read.json('./data.json').withColumn(\"persons\", explode(col(\"persons\"))).select(\n",
    "    \"persons.name\",\n",
    "    \"persons.adress\",\n",
    "    \"persons.phone\",\n",
    "    \"persons.email\",\n",
    "    \"persons.age\",\n",
    "    \"persons.gender\",\n",
    ")\n",
    "\n",
    "df = persons.toPandas().apply(preprocessing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    users.insert_one({\n",
    "        'phone': row['phone'],\n",
    "        'email': row['email'],\n",
    "        'sexe': row['gender'],\n",
    "        'age': row['age'],\n",
    "        'firstname': row['firstname'],\n",
    "        'lastname': row['lastname'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for document in users.find({}):\n",
    "#     print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows = db['shows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(header='True', inferSchema='True', delimiter=',') \\\n",
    "  .csv(\"show.csv\") \\\n",
    "  .drop('id_location', 'id_show', 'artist')\n",
    "df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = spark.read.json('./locations.json', multiLine=True) \\\n",
    "    .withColumn(\"features\", explode(col(\"features.geometry.coordinates\"))) \\\n",
    "    .withColumn(\"lat\", col('features').getItem(0).alias('lat')) \\\n",
    "    .withColumn(\"long\", col('features').getItem(1).alias('long')) \\\n",
    "    .drop(\"type\", \"features\") \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = date(2022, 6, 1)\n",
    "end = date(2022, 9, 1)\n",
    "date_list = []\n",
    "\n",
    "while current < end:\n",
    "    for item in pd.date_range(current+pd.DateOffset(hours=10), current+pd.DateOffset(hours=24), freq='2H'):\n",
    "        date_list.append(str(item))\n",
    "    current += timedelta(days=1)\n",
    "\n",
    "random.shuffle(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = spark.read.json('./data.json').withColumn(\"artists\", explode(col(\"artists\"))).select(\n",
    "    \"artists.firstname\",\n",
    "    \"artists.lastname\",\n",
    ")\n",
    "\n",
    "artists = artists.toPandas().sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (127861233.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Die Go Die\\AppData\\Local\\Temp\\ipykernel_8448\\127861233.py\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    'date' : new ISODate(date_list[index]),\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    lat, long = locations.loc[index % locations.shape[0]].values\n",
    "    shows.insert_one({\n",
    "        'title': row['nom'],\n",
    "        'type': row['type'],\n",
    "        'artist': ' '.join(artists.loc[index % artists.shape[0]].values),\n",
    "        'nbPlace': row['nb_place'],\n",
    "        'lat': lat,\n",
    "        'long': long,\n",
    "        'date' : date_list[index],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for document in shows.find({}):\n",
    "#    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parkings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkings = db['parkings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de 2 générateurs identiques\n",
    "rows, get_nb_rows = tee(spark.read.option(\"multiline\", \"true\").json('parkings.json').toPandas().iterrows())\n",
    "nb_parkings = len(list((get_nb_rows)))\n",
    "\n",
    "# Liste de booleans aléatoires avec 25% de False\n",
    "list_pmr = list(map(lambda x: x < 0.75, [random.random() for _ in range(nb_parkings)]))\n",
    "\n",
    "description: str\n",
    "# Boucle sur 3 list différentes, les parkings et 2 listes aléatoires pour générer des booleans\n",
    "# Avec Spark, je peux directement unpack le json, c'est bizarre mais ca marche\n",
    "for (_, (((long, lat), _), (description, name), _)), pmr, bus in zip(rows, list_pmr, reversed(list_pmr)):\n",
    "    \n",
    "    try:\n",
    "        slot = int(re.search(r'\\*\\*(\\d+)\\*\\*', description).group(1))\n",
    "        \n",
    "        if not slot:\n",
    "            slot = 'unknown'\n",
    "    except: slot = 'unknown'\n",
    "    \n",
    "    parkings.insert_one({\n",
    "        'type': 'voiture',\n",
    "        'name': name,\n",
    "        'nbslots': slot,\n",
    "        'paying': not 'gratuit' in description.lower(),\n",
    "        'busFestiv': bus,\n",
    "        'pmr': pmr,\n",
    "        'lat': lat,\n",
    "        'long': long,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le choix multiple pour  la categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7ff586f0444400918f77424ece8809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='performance'), Checkbox(value=False, description='indiscipli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a0d7e0cc1e4c2d9e4ec634542516d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Artiste:', index=15, options=('Jose Pierce', 'Kim Martinez', 'Tammy Fernandez', 'Malik H…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828ae42174b6400b9347523a6884e06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(DatePicker(value=datetime.date(2022, 6, 1), description='Date début'), IntText(value=0, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09f8cadc5bd4a43b474b53400e15399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(DatePicker(value=datetime.date(2022, 8, 31), description='Date fin'), IntText(value=0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artists = [document for document in shows.find({}, {'artist' : 1, '_id' : 0})]\n",
    "artists = list(set(map(lambda artists: artists[\"artist\"], artists)))\n",
    "\n",
    "\n",
    "date_start = widgets.DatePicker(\n",
    "    description='Date début',\n",
    "    disabled=False,\n",
    "    value = datetime.date(2022,6,1)\n",
    ")\n",
    "date_end = widgets.DatePicker(\n",
    "    description='Date fin',\n",
    "    disabled=False,\n",
    "    value = datetime.date(2022,8,31)\n",
    ")\n",
    "hour_start = widgets.IntText(\n",
    "    value='0',\n",
    "    description='Heure début:',\n",
    "    disabled=False\n",
    ")\n",
    "hour_end = widgets.IntText(\n",
    "    value='0',\n",
    "    description='Heure fin:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "artiste = widgets.Dropdown(\n",
    "    options=artists,\n",
    "    value='Aaron Adams',\n",
    "    description='Artiste:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "data = [\"performance\", \"indiscipline\", \"spectacle\", \"théatre\", \"danse\", \"Installation photographique\"]\n",
    "checkboxes = [widgets.Checkbox(value=False, description=label) for label in data]\n",
    "output1 = widgets.VBox(children=checkboxes)\n",
    "display(output1, artiste, widgets.HBox(children=[date_start, hour_start]), widgets.HBox(children=[date_end, hour_end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('638cbec6245ebe03dbdb816d'), 'title': 'Village du off', 'type': 'indiscipline', 'artist': 'Keith Myers', 'nbPlace': 192, 'lat': 4.809739869781737, 'long': 43.946121568039445, 'date': '2022-08-07 12:00:00'}\n",
      "{'_id': ObjectId('638cbec6245ebe03dbdb81bd'), 'title': 'Conservatoire du Grand Avignon', 'type': 'danse', 'artist': 'Keith Myers', 'nbPlace': 231, 'lat': 4.807018916829577, 'long': 43.9461076953134, 'date': '2022-06-12 14:00:00'}\n"
     ]
    }
   ],
   "source": [
    "for document in shows.find({'type' : { '$in' : [i.description for i in checkboxes if i.value == True]}, \n",
    "                            'date' : {'$gte' : date_start.value.strftime(\"%Y-%m-%d \") + str(timedelta(hours=hour_start.value)), \n",
    "                                      '$lt' : date_end.value.strftime(\"%Y-%m-%d \") + str(timedelta(hours=hour_end.value))},\n",
    "                            'artist' : artiste.value}):\n",
    "    print(document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4a5ba753e9e17d8144c6e58060ee76a0f979039f4bebfbd95f36ef0148a107c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
